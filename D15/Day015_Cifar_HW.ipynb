{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 52s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  #keras自带的MNIST数据集加载方法\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "#OneHotEncoder()也就是说，一个属性如果有N个可取值，它就可以扩充为N个属性，每个样本的这N个属性中，只能有一个为1，表示该样本的该属性属于这个类别，其余扩展属性都为0。\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "D:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 1.4703 - accuracy: 0.4860\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.9999 - accuracy: 0.6429\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 161s 3ms/step - loss: 0.8246 - accuracy: 0.7098\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.6991 - accuracy: 0.7573\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 150s 3ms/step - loss: 0.5674 - accuracy: 0.8029\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.4466 - accuracy: 0.8469\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 168s 3ms/step - loss: 0.3422 - accuracy: 0.8831\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.2576 - accuracy: 0.9114\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.1993 - accuracy: 0.9323\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 169s 3ms/step - loss: 0.1583 - accuracy: 0.9462\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 0.1421 - accuracy: 0.9523\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.1342 - accuracy: 0.9546\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.1052 - accuracy: 0.9638\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 0.0940 - accuracy: 0.9671\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0991 - accuracy: 0.9662\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0880 - accuracy: 0.9707\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0808 - accuracy: 0.9725\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0715 - accuracy: 0.9756\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0652 - accuracy: 0.9781\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0717 - accuracy: 0.9754\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0617 - accuracy: 0.9795\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0580 - accuracy: 0.9804\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0635 - accuracy: 0.9791\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0537 - accuracy: 0.9825\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0533 - accuracy: 0.9823\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0576 - accuracy: 0.9811\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0503 - accuracy: 0.9836\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0429 - accuracy: 0.9855\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0397 - accuracy: 0.9874\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0475 - accuracy: 0.9838\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0492 - accuracy: 0.9835\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0361 - accuracy: 0.9882\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0436 - accuracy: 0.9862\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0416 - accuracy: 0.9862\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0457 - accuracy: 0.9847\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0369 - accuracy: 0.9881\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.0331 - accuracy: 0.9891\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0363 - accuracy: 0.9880\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0369 - accuracy: 0.9881\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0277 - accuracy: 0.9908\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0305 - accuracy: 0.9900\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0390 - accuracy: 0.9877\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.0387 - accuracy: 0.9879\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 137s 3ms/step - loss: 0.0327 - accuracy: 0.9901\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0249 - accuracy: 0.9923\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0304 - accuracy: 0.9902\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0270 - accuracy: 0.9918\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0341 - accuracy: 0.9889\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0258 - accuracy: 0.9918\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 135s 3ms/step - loss: 0.0236 - accuracy: 0.9921\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 135s 3ms/step - loss: 0.0339 - accuracy: 0.9897\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 143s 3ms/step - loss: 0.0229 - accuracy: 0.9928\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0237 - accuracy: 0.9923\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 161s 3ms/step - loss: 0.0233 - accuracy: 0.9924\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 158s 3ms/step - loss: 0.0294 - accuracy: 0.9909\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.0325 - accuracy: 0.9904\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.0258 - accuracy: 0.9921\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.0245 - accuracy: 0.9930\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.0238 - accuracy: 0.9926\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 152s 3ms/step - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 137s 3ms/step - loss: 0.0259 - accuracy: 0.9920\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 137s 3ms/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 137s 3ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 137s 3ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0217 - accuracy: 0.9934\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0225 - accuracy: 0.9932\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0208 - accuracy: 0.9935\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 136s 3ms/step - loss: 0.0164 - accuracy: 0.9948\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.0177 - accuracy: 0.9943\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 169s 3ms/step - loss: 0.0179 - accuracy: 0.9943\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 166s 3ms/step - loss: 0.0242 - accuracy: 0.9930\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 160s 3ms/step - loss: 0.0231 - accuracy: 0.9929\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 157s 3ms/step - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.0164 - accuracy: 0.9948\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0187 - accuracy: 0.9943\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0172 - accuracy: 0.9946\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0157 - accuracy: 0.9952\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0198 - accuracy: 0.9943\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.0213 - accuracy: 0.9939\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0216 - accuracy: 0.9936\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0195 - accuracy: 0.9942\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0202 - accuracy: 0.9940\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0147 - accuracy: 0.9960\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0140 - accuracy: 0.9959\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0099 - accuracy: 0.9968\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0148 - accuracy: 0.9954\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 0.0217 - accuracy: 0.9938\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0232 - accuracy: 0.9932\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.0172 - accuracy: 0.9949\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0163 - accuracy: 0.9953\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.0150 - accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a70981add8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "#classifier.add(Convolution2D('自己設計參數'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "#classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Convolution2D(32,kernel_size=(3, 3), padding='same',input_shape=(32,32,3),activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "#classifier.add(Convolution2D('自己設計參數'))\n",
    "#classifier.add(BatchNormalization())\n",
    "classifier.add(Convolution2D(64,kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))#放在這\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "#classifier.add(Dense('自己設計FC層參數')) #output_dim=100,activation=relu\n",
    "classifier.add(Dense(output_dim=128,activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "#classifier.add(Dense(output_dim=10,activation='輸出函數應該用什麼？'))\n",
    "#Softmax函數能將輸出值總合統整成1，轉換成機率的型態，通常⽤用於多類的分類器輸出。\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy  \n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "'''\n",
    "#optimizer: 优化器 \n",
    "#loss:损失函数,可以用自带的,也可以自定义.如果模型有多个输出,可以传入一个字典或者损失列表,模型降会把这些损失加在一起\n",
    "metrics: 评价函数,与损失函数类似,只不过评价函数的结果不会用于训练过程中\n",
    ",可以传递已有的评价函数名称,或者传递一个自定义的theano/tensorflow函数来使用\n",
    ",自带的评价函数有:binary_accuracy(y_true,y_pred)\n",
    ", categorical_accuracy(y_true,y_pred)\n",
    ",sparse_categorical_accuracy(y_true,y_pred)\n",
    ", top_k_categorical_accuracy(y_true,y_pred,k=5).\n",
    "自定义评价函数应该在编译的时候compile传递进去,该函数需要以(y_true,y_pred)作为输入参数,并返回一个张量作为输出结果.\n",
    "loss_weights:可选项,是一个list或字典,指定不同的损失的系数\n",
    "'''\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0284973e-15, 1.3892687e-22, 3.5717175e-26, 1.0000000e+00,\n",
       "        2.2147266e-09, 1.3937302e-26, 3.9160554e-24, 7.0002900e-26,\n",
       "        4.9680798e-18, 1.1462182e-28]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
